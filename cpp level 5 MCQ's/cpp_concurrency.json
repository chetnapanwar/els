{
  "message": "Development-Programming Fundamentals - Cpp Concurrency",
  "questions": [
    {
      "id": "cpp_sync_01",
      "topic": "Concurrency - Memory Model",
      "level": 5,
      "question": "What is the difference between `std::memory_order_acquire` and `std::memory_order_release` in a producer-consumer scenario using atomic variables?",
      "options": [
        "A 'release' operation on a variable in the producer ensures all previous writes are visible to a thread performing an 'acquire' operation on that same variable.",
        "They are identical and just used for different thread IDs.",
        "Acquire is for writing and Release is for reading.",
        "Release clears the cache, while Acquire pre-fetches the variables."
      ],
      "answer": "A 'release' operation on a variable in the producer ensures all previous writes are visible to a thread performing an 'acquire' operation on that same variable.",
      "explanation": "This establishes a 'synchronizes-with' relationship. Release ensures preceding memory ops move no further than the atomic write; Acquire ensures subsequent memory ops stay after the atomic read."
    },
    {
      "id": "cpp_sync_02",
      "topic": "Concurrency - Lock-free",
      "level": 5,
      "question": "What is the 'ABA Problem' in lock-free programming, and how is it commonly solved in C++?",
      "options": [
        "A value changes from A to B and back to A; solved using tagged pointers (atomic versioning).",
        "Two threads locking in different orders; solved using `std::lock()`.",
        "Atomic operations failing due to hardware limits; solved by using Mutex as fallback.",
        "Memory corruption during thread exit; solved by join/detach."
      ],
      "answer": "A value changes from A to B and back to A; solved using tagged pointers (atomic versioning).",
      "explanation": "CAS (Compare-and-swap) might succeed incorrectly if a node was deleted and re-instantiated at the same address. Solve it by adding a counter to the pointer (tagging) or using C++20's `std::atomic<std::shared_ptr<T>>`."
    },
    {
      "id": "cpp_sync_03",
      "topic": "Concurrency - Coroutines",
      "level": 5,
      "question": "In C++20 Coroutines, what is the 'Promise Object' responsible for?",
      "options": [
        "Handling the state and return value/exception of the coroutine from within the coroutine body.",
        "Executing the coroutine on a specific thread pool.",
        "Representing the handle held by the caller to resume the coroutine.",
        "Automatically deleting the coroutine stack frame."
      ],
      "answer": "Handling the state and return value/exception of the coroutine from within the coroutine body.",
      "explanation": "The Promise Object defines the behavior (suspend/resume/result) that the coroutine type must satisfy. The `coroutine_handle` is the external interface for the caller."
    },
    {
      "id": "cpp_sync_04",
      "topic": "Concurrency - Futex",
      "level": 5,
      "question": "What is a 'Futex' (Fast Userspace Mutex) and how does it optimize locking in Linux/Unix environments?",
      "options": [
        "It attempts to acquire the lock in userspace using atomic operations and only invokes a kernel context switch if there is contention.",
        "It's a specialized hardware instruction for 128-bit locks.",
        "It's a lock that is always handled by the kernel to ensure fairness.",
        "It is a C++20 feature that replaces `std::mutex` entirely."
      ],
      "answer": "It attempts to acquire the lock in userspace using atomic operations and only invokes a kernel context switch if there is contention.",
      "explanation": "Standard mutexes once always involved the kernel. Futexes reduce overhead by staying in userspace for the 'best case' (uncontended lock)."
    },
    {
      "id": "cpp_sync_05",
      "topic": "Concurrency - std::stop_token",
      "level": 5,
      "question": "What is the primary benefit of C++20's `std::jthread` and `std::stop_token`?",
      "options": [
        "Cooperative cancellation and automatic joining on destruction.",
        "It makes the thread run in real-time priority automatically.",
        "It prevents deadlocks by detecting circular dependencies.",
        "It allows threads to share local stack variables safely."
      ],
      "answer": "Cooperative cancellation and automatic joining on destruction.",
      "explanation": "`std::jthread` is 'joining thread'. It automatically joins if it's still joinable when destroyed. `stop_token` provides a thread-safe way to request a thread to stop working."
    },
    {
      "id": "cpp_sync_06",
      "topic": "Concurrency - Double-Checked Locking",
      "level": 5,
      "question": "Why was the traditional 'Double-Checked Locking' pattern broken prior to C++11, and how is it correctly implemented now?",
      "options": [
        "Compiler reordering and lack of memory barriers could allow a thread to see a partially constructed object; fixed by C++11's atomic memory model or 'magic statics'.",
        "It caused a CPU branch misprediction; fixed by using better CPUs.",
        "The `if` condition was not thread-safe; fixed by using `std::mutex` twice.",
        "It was never broken; developers just used it incorrectly."
      ],
      "answer": "Compiler reordering and lack of memory barriers could allow a thread to see a partially constructed object; fixed by C++11's atomic memory model or 'magic statics'.",
      "explanation": "C++11 guaranteed that local static variables are initialized in a thread-safe manner ('Magic Statics'), making DCLP mostly obsolete for singletons."
    },
    {
      "id": "cpp_sync_07",
      "topic": "Concurrency - Relaxed Ordering",
      "level": 5,
      "question": "When is `std::memory_order_relaxed` safe and appropriate to use?",
      "options": [
        "For independent counters (like reference increments) where intra-thread ordering doesn't matter and there are no dependencies on other memory.",
        "For all synchronization to maximize speed.",
        "When using Mutex-protected variables.",
        "It is never safe to use in production code."
      ],
      "answer": "For independent counters (like reference increments) where intra-thread ordering doesn't matter and there are no dependencies on other memory.",
      "explanation": "Relaxed ordering only guarantees atomicity and modification order of that specific variable. It provides no synchronization with other memory locations."
    },
    {
      "id": "cpp_sync_08",
      "topic": "Concurrency - Thread Sanitizer (TSan)",
      "level": 5,
      "question": "How does Thread Sanitizer (TSan) detect data races at runtime?",
      "options": [
        "It instruments memory accesses and utilizes shadow memory to track 'happens-before' relationships.",
        "It periodically pauses all threads and checks for overlap.",
        "It uses hardware debug registers to trap concurrent access.",
        "It only checks for deadlocks, not data races."
      ],
      "answer": "It instruments memory accesses and utilizes shadow memory to track 'happens-before' relationships.",
      "explanation": "TSan adds code to check every load/store against a state stored in shadow memory, which keeps track of which threads accessed which bytes and when."
    },
    {
      "id": "cpp_sync_09",
      "topic": "Concurrency - latch and barrier",
      "level": 5,
      "question": "In C++20, what is the difference between `std::latch` and `std::barrier`?",
      "options": [
        "A latch is a one-time use countdown; a barrier is reusable and can execute a completion phase.",
        "A latch is for threads; a barrier is for processes.",
        "A barrier is faster than a latch.",
        "There is no difference; they are aliases for the same type."
      ],
      "answer": "A latch is a one-time use countdown; a barrier is reusable and can execute a completion phase.",
      "explanation": "Latches are simple countdowns. Barriers allow a set of threads to synchronize multiple times in phases (useful for iterative parallel algorithms)."
    },
    {
      "id": "cpp_sync_10",
      "topic": "Concurrency - Task Parallelism",
      "level": 5,
      "question": "What is the primary drawback of `std::async(std::launch::async, ...)` when spawning thousands of tasks?",
      "options": [
        "It typically maps 1:1 to OS threads, which can lead to high context-switch overhead and potential thread exhaustion.",
        "It cannot return a value from the thread.",
        "It is limited to 64 concurrent tasks on Windows.",
        "It only works with global functions, not lambdas."
      ],
      "answer": "It typically maps 1:1 to OS threads, which can lead to high context-switch overhead and potential thread exhaustion.",
      "explanation": "Standard library implementations usually don't provide a sophisticated thread-stealing scheduler with `std::async`. For massive parallelism, a custom thread pool is usually preferred."
    }
  ]
}